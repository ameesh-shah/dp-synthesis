{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8599c7a3",
   "metadata": {},
   "source": [
    "# Preliminaries\n",
    "\n",
    "The following notebook contains code adapted from the Wrench tutorials (https://github.com/JieyuZ2/wrench.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39a3fa92",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "#%autoreload 2\n",
    "import os\n",
    "\n",
    "import wrench.wrench as wrnch\n",
    "# import spacy\n",
    "import numpy as np\n",
    "import nltk\n",
    "\n",
    "import logging\n",
    "import torch\n",
    "\n",
    "from wrench.wrench.dataset import load_dataset\n",
    "from wrench.wrench.logging import LoggingHandler\n",
    "from wrench.wrench.endmodel import MLPModel\n",
    "from wrench.wrench.labelmodel import MajorityVoting, FlyingSquid\n",
    "from typing import Any, List, Optional, Union, Callable\n",
    "\n",
    "#### Just some code to print debug information to stdout\n",
    "logging.basicConfig(format='%(asctime)s - %(message)s',\n",
    "                    datefmt='%Y-%m-%d %H:%M:%S',\n",
    "                    level=logging.INFO,\n",
    "                    handlers=[LoggingHandler()])\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71281672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipywidgets in /home/ameesh/anaconda3/lib/python3.9/site-packages (7.6.5)\n",
      "Requirement already satisfied: ipython>=4.0.0 in /home/ameesh/anaconda3/lib/python3.9/site-packages (from ipywidgets) (7.29.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /home/ameesh/anaconda3/lib/python3.9/site-packages (from ipywidgets) (5.1.0)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in /home/ameesh/anaconda3/lib/python3.9/site-packages (from ipywidgets) (6.4.1)\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in /home/ameesh/anaconda3/lib/python3.9/site-packages (from ipywidgets) (3.5.1)\n",
      "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /home/ameesh/anaconda3/lib/python3.9/site-packages (from ipywidgets) (1.0.0)\n",
      "Requirement already satisfied: ipython-genutils~=0.2.0 in /home/ameesh/anaconda3/lib/python3.9/site-packages (from ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in /home/ameesh/anaconda3/lib/python3.9/site-packages (from ipywidgets) (5.1.3)\n",
      "Requirement already satisfied: tornado<7.0,>=4.2 in /home/ameesh/anaconda3/lib/python3.9/site-packages (from ipykernel>=4.5.1->ipywidgets) (6.1)\n",
      "Requirement already satisfied: debugpy<2.0,>=1.0.0 in /home/ameesh/anaconda3/lib/python3.9/site-packages (from ipykernel>=4.5.1->ipywidgets) (1.4.1)\n",
      "Requirement already satisfied: matplotlib-inline<0.2.0,>=0.1.0 in /home/ameesh/anaconda3/lib/python3.9/site-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.2)\n",
      "Requirement already satisfied: jupyter-client<8.0 in /home/ameesh/anaconda3/lib/python3.9/site-packages (from ipykernel>=4.5.1->ipywidgets) (6.1.12)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /home/ameesh/anaconda3/lib/python3.9/site-packages (from ipython>=4.0.0->ipywidgets) (3.0.20)\n",
      "Requirement already satisfied: decorator in /home/ameesh/anaconda3/lib/python3.9/site-packages (from ipython>=4.0.0->ipywidgets) (5.1.0)\n",
      "Requirement already satisfied: backcall in /home/ameesh/anaconda3/lib/python3.9/site-packages (from ipython>=4.0.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /home/ameesh/anaconda3/lib/python3.9/site-packages (from ipython>=4.0.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: pygments in /home/ameesh/anaconda3/lib/python3.9/site-packages (from ipython>=4.0.0->ipywidgets) (2.10.0)\n",
      "Requirement already satisfied: setuptools>=18.5 in /home/ameesh/anaconda3/lib/python3.9/site-packages (from ipython>=4.0.0->ipywidgets) (58.0.4)\n",
      "Requirement already satisfied: pickleshare in /home/ameesh/anaconda3/lib/python3.9/site-packages (from ipython>=4.0.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/ameesh/anaconda3/lib/python3.9/site-packages (from ipython>=4.0.0->ipywidgets) (0.18.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /home/ameesh/anaconda3/lib/python3.9/site-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets) (0.8.2)\n",
      "Requirement already satisfied: pyzmq>=13 in /home/ameesh/anaconda3/lib/python3.9/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (22.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/ameesh/anaconda3/lib/python3.9/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (2.8.2)\n",
      "Requirement already satisfied: jupyter-core>=4.6.0 in /home/ameesh/anaconda3/lib/python3.9/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (4.8.1)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /home/ameesh/anaconda3/lib/python3.9/site-packages (from nbformat>=4.2.0->ipywidgets) (3.2.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /home/ameesh/anaconda3/lib/python3.9/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (0.18.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /home/ameesh/anaconda3/lib/python3.9/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (21.2.0)\n",
      "Requirement already satisfied: six>=1.11.0 in /home/ameesh/anaconda3/lib/python3.9/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (1.16.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/ameesh/anaconda3/lib/python3.9/site-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /home/ameesh/anaconda3/lib/python3.9/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets) (0.2.5)\n",
      "Requirement already satisfied: notebook>=4.4.1 in /home/ameesh/anaconda3/lib/python3.9/site-packages (from widgetsnbextension~=3.5.0->ipywidgets) (6.4.5)\n",
      "Requirement already satisfied: prometheus-client in /home/ameesh/anaconda3/lib/python3.9/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.11.0)\n",
      "Requirement already satisfied: Send2Trash>=1.5.0 in /home/ameesh/anaconda3/lib/python3.9/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.8.0)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /home/ameesh/anaconda3/lib/python3.9/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.9.4)\n",
      "Requirement already satisfied: jinja2 in /home/ameesh/anaconda3/lib/python3.9/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.11.3)\n",
      "Requirement already satisfied: nbconvert in /home/ameesh/anaconda3/lib/python3.9/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (6.1.0)\n",
      "Requirement already satisfied: argon2-cffi in /home/ameesh/anaconda3/lib/python3.9/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (20.1.0)\n",
      "Requirement already satisfied: cffi>=1.0.0 in /home/ameesh/anaconda3/lib/python3.9/site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.14.6)\n",
      "Requirement already satisfied: pycparser in /home/ameesh/anaconda3/lib/python3.9/site-packages (from cffi>=1.0.0->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.20)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /home/ameesh/anaconda3/lib/python3.9/site-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.1.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in /home/ameesh/anaconda3/lib/python3.9/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.1.2)\n",
      "Requirement already satisfied: defusedxml in /home/ameesh/anaconda3/lib/python3.9/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.7.1)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in /home/ameesh/anaconda3/lib/python3.9/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.5.3)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /home/ameesh/anaconda3/lib/python3.9/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.4.3)\n",
      "Requirement already satisfied: testpath in /home/ameesh/anaconda3/lib/python3.9/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.5.0)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /home/ameesh/anaconda3/lib/python3.9/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: bleach in /home/ameesh/anaconda3/lib/python3.9/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (4.0.0)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /home/ameesh/anaconda3/lib/python3.9/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.3)\n",
      "Requirement already satisfied: async-generator in /home/ameesh/anaconda3/lib/python3.9/site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.10)\n",
      "Requirement already satisfied: nest-asyncio in /home/ameesh/anaconda3/lib/python3.9/site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.5.1)\n",
      "Requirement already satisfied: webencodings in /home/ameesh/anaconda3/lib/python3.9/site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.5.1)\n",
      "Requirement already satisfied: packaging in /home/ameesh/anaconda3/lib/python3.9/site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (21.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/ameesh/anaconda3/lib/python3.9/site-packages (from packaging->bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (3.0.4)\n",
      "Enabling notebook extension jupyter-js-widgets/extension...\n",
      "      - Validating: \u001b[32mOK\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install ipywidgets\n",
    "!jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69ceb01",
   "metadata": {},
   "source": [
    "# Creating Labeling Functions\n",
    "\n",
    "First, we need to load our data in to the Wrench-provided pipeline. A set of prior labeling features are provided in the dataset to use in lieu of user-provided labeling functions; in order to use them, set extract_feature to True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d91e5653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-03-29 11:26:24 - loading data from data/youtube/train.json\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73a97a77f0cb422b959da535c3784b7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1686 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-03-29 11:26:24 - loading data from data/youtube/valid.json\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b80ab9500f7418083b533a3c31dbd53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/120 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-03-29 11:26:24 - loading data from data/youtube/test.json\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02da9a6a531c4700979417cc0df5d069",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-03-29 11:26:24 - loading features from data/youtube/train_bert.pkl\n",
      "2022-03-29 11:26:24 - loading features from data/youtube/valid_bert.pkl\n",
      "2022-03-29 11:26:24 - loading features from data/youtube/test_bert.pkl\n"
     ]
    }
   ],
   "source": [
    "# Set up the location from which to load the data.\n",
    "dataset_home = './data'\n",
    "data = 'youtube'\n",
    "#### Extract data features using pre-trained BERT model and cache it\n",
    "extract_fn = 'bert'\n",
    "model_name = 'bert-base-cased'\n",
    "\n",
    "#Note: you can set extract_features to True if you'd like to use pre-set Labeling Function outputs.\n",
    "train_data, valid_data, test_data = load_dataset(dataset_home, data, extract_feature=True, extract_fn=extract_fn,\n",
    "                                                 cache_name=extract_fn, model_name=model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0af09eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from synthesis import TEXT_SANDBOX_GRAMMAR, TextLabelFunction, enumerate_from_grammar\n",
    "# defining lfs\n",
    "def lf1(data):\n",
    "    if any(word in data for word in [\"<br\",\"amp\",\"Follow\",\"check\",\"channel\",\"plz\",\"PLEASE\",\"OUT\", \"fuck\", \"out\", \"SUBSCRIBE\" \"Check\",\"guys\", \"my\",\"My\", \"subscribe\", \"http\", \"https\", \"please\", \"href\", \"money\",\"$\", \"making\", \"per\"]):\n",
    "        return np.array(1)\n",
    "    else:\n",
    "        return np.array(-1)\n",
    "# def lf2(data):\n",
    "#     if \"my channel\" in data or \"leave some\" in data  or \"EXTRAORDINARY website\" in data or \"You can make\" in data or \"make money online\" in data:\n",
    "#         return np.array(1)\n",
    "#     else:\n",
    "#         return np.array(-1)\n",
    "# def lf3(data):\n",
    "#     if \"like this\" in data :\n",
    "#         return np.array(0)\n",
    "#     else:\n",
    "#         return np.array(-1)\n",
    "    \n",
    "def lf2(data):\n",
    "    if any(word in data for word in [\"!!!!\",\"PSY\",\"like\", \"song\",\"video\", \"music\" ]):\n",
    "        return np.array(0)\n",
    "    else:\n",
    "        return np.array(-1)\n",
    "\n",
    "# def lf5(data):\n",
    "#     if any(word in data for word in [\"PSY\",\"like\", \"song\" ]):\n",
    "#         return np.array(0)\n",
    "#     else:\n",
    "#         return np.array(-1)\n",
    "\n",
    "# def lf6(data):\n",
    "#     if any(word in data for word in [\"video\", \"music\"]):\n",
    "#         return np.array(0)\n",
    "#     else:\n",
    "#         return np.array(-1)\n",
    "fxn_gnr = enumerate_from_grammar(TEXT_SANDBOX_GRAMMAR, TextLabelFunction)\n",
    "synth_fxn1 = next(fxn_gnr)\n",
    "synth_fxn2 = next(fxn_gnr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e56e5b5",
   "metadata": {},
   "source": [
    "Now, if you're going to manually generate and provide Labeling Functions, we're going to consider some ways of doing so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76f21b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Generate procedural labeling functions, using the LF generation defined by WRENCH.\n",
    "from wrench.wrench.synthetic import ConditionalIndependentGenerator, NGramLFGenerator\n",
    "\n",
    "#### Generate procedural labeling functions\n",
    "# generator = NGramLFGenerator(dataset=train_data, min_acc_gain=0.1, min_support=0.01, ngram_range=(1, 2))\n",
    "# applier = generator.generate(mode='correlated', n_lfs=10)\n",
    "# L_test = applier.apply(test_data)\n",
    "# L_train = applier.apply(train_data)\n",
    "# print(len(train_data.examples))\n",
    "# print(L_train.shape)\n",
    "\n",
    "from labelfunction import LabelFunctionSet, RandomLFGenerator\n",
    "# ## Use our API to include and apply custom labeling functions.\n",
    "# LF_genr = RandomLFGenerator(num_functions=10, output_size=2) # 2 is the output size for binary classes\n",
    "# # As a placeholder, we're just going to generate 'random' labeling functions.\n",
    "# # If we want to use our own, we can just replace 'random_lfs' with our list of LFs!\n",
    "# random_lfs = LF_genr.get_random_lfs()\n",
    "\n",
    "LFSet = LabelFunctionSet()\n",
    "#LFSet.add_function(lf1)\n",
    "LFSet.add_function(synth_fxn2.generate_synthesized_function)\n",
    "\n",
    "\n",
    "L_test = LFSet.apply_labels(test_data)\n",
    "L_train = LFSet.apply_labels(train_data)\n",
    "\n",
    "#### Evaluate label model on real-world dataset with semi-synthetic labeling functions\n",
    "label_model = MajorityVoting()\n",
    "label_model.fit(dataset_train=L_train, dataset_valid=valid_data)\n",
    "target_value = label_model.test(test_data, metric_fn='acc')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a459c260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ee2556",
   "metadata": {},
   "source": [
    "#### Make sure you run a cell to generate the labeled data if you're providing manual functions!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553e5868",
   "metadata": {},
   "source": [
    "# Downstream Model Training Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4120320",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 1.        ],\n",
       "       [0.33333333, 0.66666667],\n",
       "       [0.5       , 0.5       ],\n",
       "       ...,\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Generate soft training label via a label model\n",
    "soft_label = label_model.predict_proba(train_data)\n",
    "soft_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ece07a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf6adacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Train a MLP classifier with soft label\n",
    "device = torch.device('cpu')\n",
    "n_steps = 100000\n",
    "batch_size = 128\n",
    "test_batch_size = 1000 \n",
    "patience = 200\n",
    "evaluation_step = 50\n",
    "target='acc'\n",
    "\n",
    "model = MLPModel(n_steps=n_steps, batch_size=batch_size, test_batch_size=test_batch_size)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36030b34",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5adb0cf54abf4e37aaf95a209f845297",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[TRAIN] MLP Classifier:   0%|                                                                                 â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's actually train the model here.\n",
    "history = model.fit(dataset_train=train_data, dataset_valid=valid_data, y_train=soft_label, \n",
    "                    device=device, metric=target, patience=patience, evaluation_step=evaluation_step)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c4f5011d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.916\n"
     ]
    }
   ],
   "source": [
    "#### Evaluate the trained model\n",
    "metric_value = model.test(test_data, target)\n",
    "print(metric_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4e4232a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.916\n"
     ]
    }
   ],
   "source": [
    "#### Evaluate the trained model\n",
    "metric_value = model.test(test_data, target)\n",
    "print(metric_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87396e5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wrench",
   "language": "python",
   "name": "wrench"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
