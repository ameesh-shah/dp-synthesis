{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cbf97eac",
   "metadata": {},
   "source": [
    "# Preliminaries\n",
    "\n",
    "The following notebook contains code adapted from the Wrench tutorials (https://github.com/JieyuZ2/wrench.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3c5f964",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wrench.wrench as wrnch\n",
    "import spacy\n",
    "import numpy as np\n",
    "import nltk\n",
    "\n",
    "import logging\n",
    "import torch\n",
    "\n",
    "from wrench.wrench.dataset import load_dataset\n",
    "from wrench.wrench.logging import LoggingHandler\n",
    "from wrench.wrench.endmodel import MLPModel\n",
    "from wrench.wrench.labelmodel import MajorityVoting, FlyingSquid\n",
    "\n",
    "#### Just some code to print debug information to stdout\n",
    "logging.basicConfig(format='%(asctime)s - %(message)s',\n",
    "                    datefmt='%Y-%m-%d %H:%M:%S',\n",
    "                    level=logging.INFO,\n",
    "                    handlers=[LoggingHandler()])\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baef78a1",
   "metadata": {},
   "source": [
    "# Creating Labeling Functions\n",
    "\n",
    "First, we need to load our data in to the Wrench-provided pipeline. A set of prior labeling features are provided in the dataset to use in lieu of user-provided labeling functions; in order to use them, set extract_feature to True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "63c11b6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-03-15 12:48:57 - loading data from data/youtube/train.json\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0b4785758604c639f6a2249ce22b6fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1686 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-03-15 12:48:57 - loading data from data/youtube/valid.json\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d32b2cdb01b7439c8182469feee9a033",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/120 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-03-15 12:48:57 - loading data from data/youtube/test.json\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1109696966247e5b1b9a1559d5f3df0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-03-15 12:48:57 - loading features from data/youtube/train_bert.pkl\n",
      "2022-03-15 12:48:57 - loading features from data/youtube/valid_bert.pkl\n",
      "2022-03-15 12:48:57 - loading features from data/youtube/test_bert.pkl\n"
     ]
    }
   ],
   "source": [
    "# Set up the location from which to load the data.\n",
    "dataset_home = './data'\n",
    "data = 'youtube'\n",
    "#### Extract data features using pre-trained BERT model and cache it\n",
    "extract_fn = 'bert'\n",
    "model_name = 'bert-base-cased'\n",
    "\n",
    "#Note: you can set extract_features to True if you'd like to use pre-set Labeling Function outputs.\n",
    "train_data, valid_data, test_data = load_dataset(dataset_home, data, extract_feature=True, extract_fn=extract_fn,\n",
    "                                                 cache_name=extract_fn, model_name=model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59315ffa",
   "metadata": {},
   "source": [
    "Now, if you're going to manually generate and provide Labeling Functions, we're going to consider some ways of doing so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "245b022b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Generate procedural labeling functions, using the LF generation defined by WRENCH.\n",
    "from wrench.wrench.synthetic import ConditionalIndependentGenerator, NGramLFGenerator\n",
    "\n",
    "#### Generate procedural labeling functions\n",
    "generator = NGramLFGenerator(dataset=train_data, min_acc_gain=0.1, min_support=0.01, ngram_range=(1, 2))\n",
    "applier = generator.generate(mode='correlated', n_lfs=10)\n",
    "L_test = applier.apply(test_data)\n",
    "L_train = applier.apply(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2d21d977",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now, let's reinsert the newly labeled data back into the dataset.\n",
    "# train_data, valid_data, test_data = load_dataset(dataset_home, data, extract_feature=True, extract_fn=applier.apply,\n",
    "#                                                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f56d758",
   "metadata": {},
   "source": [
    "#### Make sure you run a cell to generate the labeled data if you're providing manual functions!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1befede",
   "metadata": {},
   "source": [
    "# Wrench Training Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c2777d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Generate soft training label via a label model\n",
    "#### The weak labels provided by supervision sources are alreadly encoded in dataset object\n",
    "label_model = MajorityVoting()\n",
    "label_model.fit(dataset_train=train_data, dataset_valid=valid_data)\n",
    "soft_label = label_model.predict_proba(labeled_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3757a0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Train a MLP classifier with soft label\n",
    "device = torch.device('cuda:0')\n",
    "n_steps = 100000\n",
    "batch_size = 128\n",
    "test_batch_size = 1000 \n",
    "patience = 200\n",
    "evaluation_step = 50\n",
    "target='acc'\n",
    "\n",
    "model = MLPModel(n_steps=n_steps, batch_size=batch_size, test_batch_size=test_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "447a42c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc23736b76764081a90b181589029161",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[TRAIN] MLP Classifier:   0%|                                                                                 â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-03-15 12:51:16 - [INFO] early stop @ step 30450!\n"
     ]
    }
   ],
   "source": [
    "# Let's actually train the model here.\n",
    "history = model.fit(dataset_train=train_data, dataset_valid=valid_data, y_train=soft_label, \n",
    "                    device=device, metric=target, patience=patience, evaluation_step=evaluation_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bb3b0f3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.84\n"
     ]
    }
   ],
   "source": [
    "#### Evaluate the trained model\n",
    "metric_value = model.test(test_data, target)\n",
    "print(metric_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f777beae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wrench",
   "language": "python",
   "name": "wrench"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
